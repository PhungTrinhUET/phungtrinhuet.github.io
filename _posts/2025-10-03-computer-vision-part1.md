---
layout: post
title: "ChÆ°Æ¡ng 1: Ná»n táº£ng cá»§a Máº¡ng NÆ¡-ron NhÃ¢n táº¡o"
date: 2025-10-03 09:00 +0700
categories: [Deep Learning, Notes]
tags: [ANN, PyTorch, Feedforward, BackPropagation]
permalink: /posts/chuong-1-ann/
toc: true  
---
_Xin chÃ o má»i ngÆ°á»i, má»™t sá»‘ chá»§ Ä‘á» mÃ¬nh sáº½ chia sáº» vÃ  cÃ¹ng nhau há»c vá»›i má»i ngÆ°á»i sáº½ lÃ  AI - Computer Vision - Mong má»i ngÆ°á»i cÃ¹ng nhau há»c há»i vÃ  cÃ¹ng nhau phÃ¡t triá»ƒn...._
## KhÃ¡i niá»‡m
**Máº¡ng NÆ¡-Ron nhÃ¢n táº¡o ANN (Artificial Neural Network)** lÃ  má»™t thuáº­t toÃ¡n há»c cÃ³ giÃ¡m sÃ¡t, láº¥y cáº£m há»©ng tá»« cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a nÃ£o ngÆ°á»i. Máº¡ng nháº­n **Ä‘áº§u vÃ o** â†’ **xá»­ lÃ½ qua hÃ m kÃ­ch hoáº¡t** â†’ **kÃ­ch hoáº¡t nÆ¡-ron tiáº¿p theo** â†’ **táº¡o Ä‘áº§u ra (output)**.

## Äáº·c Ä‘iá»ƒm chÃ­nh: 
- CÃ³ nhiá»u kiáº¿n trÃºc máº¡ng chuáº©n: **MLP, CNN, RNN...**
- **Äá»‹nh lÃ½ xáº¥p xá»‰ phá»• quÃ¡t (Universal Approximation Theorem):** Má»™t máº¡ng nÆ¡-ron Ä‘á»§ lá»›n, Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘Ãºng cÃ¡ch cÃ³ thá»ƒ mÃ´ phá»ng **báº¥t ká»³ hÃ m nÃ o**, tá»« Ä‘Ã³ dá»± Ä‘oÃ¡n output tá»« input tÆ°Æ¡ng á»©ng.  
- **Huáº¥n luyá»‡n máº¡ng nÆ¡-ron:** Vá»›i táº­p dá»¯ liá»‡u cá»¥ thá»ƒ, ta xÃ¢y dá»±ng má»™t kiáº¿n trÃºc máº¡ng, Ä‘iá»u chá»‰nh trá»ng sá»‘ cho Ä‘áº¿n khi mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n káº¿t quáº£ mong muá»‘n.

## á»¨ng dá»¥ng Ä‘iá»ƒn hÃ¬nh:
- Trong **thá»‹ giÃ¡c mÃ¡y tÃ­nh**, ANN Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ phÃ¢n loáº¡i áº£nh.  
- **Cuá»™c thi ImageNet** lÃ  cá»™t má»‘c quan trá»ng: cÃ¡c mÃ´ hÃ¬nh ANN thi nhau phÃ¢n loáº¡i hÃ ng triá»‡u áº£nh, tá»· lá»‡ lá»—i giáº£m máº¡nh theo tá»«ng nÄƒm.
  
![Tá»· lá»‡ lá»—i ImageNet](/assets/img/chuong1/figure1.png)

*HÃ¬nh 1: Tá»· lá»‡ lá»—i phÃ¢n loáº¡i trong cuá»™c thi ImageNet.*

- NÄƒm 2012, **AlexNet** chiáº¿n tháº¯ng ImageNet. Tá»· lá»‡ lá»—i giáº£m máº¡nh, tháº­m chÃ­ tá»‘t hÆ¡n con ngÆ°á»i.
- Ã nghÄ©a: Máº¡ng nÆ¡-ron sÃ¢u khÃ´ng chá»‰ phÃ¢n loáº¡i áº£nh tá»‘t mÃ  cÃ²n má»Ÿ ra nhiá»u á»©ng dá»¥ng má»›i.

## á»¨ng dá»¥ng má»Ÿ rá»™ng (Generative AI)
- Sinh áº£nh tá»« vÄƒn báº£n Ä‘áº§u vÃ o.  
- Sinh áº£nh má»›i tá»« áº£nh + vÄƒn báº£n.  
- Káº¿t há»£p Ä‘a dáº¡ng dá»¯ liá»‡u (áº£nh, vÄƒn báº£n, Ã¢m thanh) Ä‘á»ƒ sinh ná»™i dung.  
- Sinh video tá»« vÄƒn báº£n hoáº·c áº£nh.  

ğŸ’¡ ÄÃ¢y chÃ­nh lÃ  Ä‘á»™ng lá»±c quan trá»ng Ä‘á»ƒ há»c vÃ  triá»ƒn khai ANN cho cÃ¡c bÃ i toÃ¡n tÃ¹y chá»‰nh.

## Ná»™i dung chÃ­nh cá»§a chÆ°Æ¡ng 1
- So sÃ¡nh **AI** vÃ  **há»c mÃ¡y truyá»n thá»‘ng**.  
- Hiá»ƒu cÃ¡c khá»‘i cÆ¡ báº£n cá»§a ANN: **feedforward, backpropagation, learning rate**.  
- Triá»ƒn khai **feedforward propagation**.  
- Triá»ƒn khai **backpropagation**.  
- Káº¿t há»£p cáº£ hai Ä‘á»ƒ huáº¥n luyá»‡n.  
- PhÃ¢n tÃ­ch tÃ¡c Ä‘á»™ng cá»§a **learning rate**.  
- TÃ³m táº¯t quÃ¡ trÃ¬nh huáº¥n luyá»‡n máº¡ng nÆ¡-ron.

## I. So sÃ¡nh trÃ­ tuá»‡ nhÃ¢n táº¡o (AI) vÃ  há»c mÃ¡y truyá»n thá»‘ng

TrÆ°á»›c Ä‘Ã¢y, cÃ¡ch tiáº¿p cáº­n Ä‘á»ƒ lÃ m há»‡ thá»‘ng â€œthÃ´ng minhâ€ lÃ  viá»‡c cÃ¡c láº­p tÃ¬nh viÃªn pháº£i viáº¿t ra thuáº­t toÃ¡n phá»©c táº¡p dá»±a trÃªn kiáº¿n thá»©c tá»« chuyÃªn gia. VÃ­ dá»¥ vá» viá»‡c Ä‘ang quan tÃ¢m Ä‘Ã©n viá»‡c nháº­n diá»‡n xem má»™t bá»©c áº£nh cÃ³ chá»©a hÃ¬nh con chÃ³ hay khÃ´ng.
Trong thiáº¿t láº­p há»c mÃ¡y truyá»n thá»‘ng (Machine Learning) thÃ¬ má»™t chuyÃªn gia ML hoáº·c má»™t chuyÃªn gia lÄ©nh vá»±c sáº½: **xÃ¡c Ä‘á»‹nh cÃ¡c Ä‘áº·c trÆ°ng (features) cáº§n Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« hÃ¬nh áº£nh -> TrÃ­ch xuáº¥t cÃ¡c Ä‘áº·c trÆ°ng Ä‘Ã³ -> ÄÆ°a vÃ o thuáº­t toÃ¡n phÃ¢n loáº¡i (SVM, Random Forest, KNNâ€¦) -> quyáº¿t Ä‘á»‹nh áº£nh cÃ³ lÃ  chÃ³ khÃ´ng.**

![Traditional Machine Learning workflow for classification](/assets/img/chuong1/figure2.png)

*HÃ¬nh 2: Traditional Machine Learning workflow for classification*

![Sample images to generate rules](/assets/img/chuong1/figure3.png)

*HÃ¬nh 3: Sample images to generate rules* 

Tá»« cÃ¡c áº£nh trÃªn, má»™t quy táº¯c Ä‘Æ¡n giáº£n cÃ³ thá»ƒ hiá»ƒu: náº¿u má»™t bá»©c áº£nh chá»©a 3 vÃ¹ng trÃ²n mÃ u Ä‘en Ä‘Æ°á»£c sáº¯p xáº¿p theo hÃ¬nh tam giÃ¡c, thÃ¬ áº£nh Ä‘Ã³ cÃ³ thá»ƒ Ä‘Æ°á»£c phÃ¢n loáº¡i lÃ  chÃ³. Tuy nhiÃªn nÃ³ láº¡i lÃ  bÃ¡nh muffin.

Háº¡n cháº¿ cá»§a phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng: 
- **Quy táº¯c thá»§ cÃ´ng**: vÃ­ dá»¥ Ä‘áº·t ra quy táº¯c â€œba vÃ²ng trÃ²n Ä‘en thÃ nh hÃ¬nh tam giÃ¡c -> chÃ³â€.
- **Váº¥n Ä‘á»**:
- Dá»… bá»‹ Ä‘Ã¡nh lá»«a (áº£nh bÃ¡nh muffin giá»‘ng máº·t chÃ³).
- Cáº§n quÃ¡ nhiá»u quy táº¯c khi hÃ¬nh áº£nh phá»©c táº¡p, thay Ä‘á»•i lá»›n.
- Chá»‰ hiá»‡u quáº£ trong mÃ´i trÆ°á»ng rÃ ng buá»™c cháº·t cháº½ (vÃ­ dá»¥: áº£nh há»™ chiáº¿u)
- KhÃ³ Ã¡p dá»¥ng cho cÃ¡c tÃ¬nh huá»‘ng Ä‘a dáº¡ng, thá»±c táº¿.

**Lá»£i tháº¿ cá»§a máº¡ng NÆ¡-ron nhÃ¢n táº¡o (ANNs):**
- Káº¿t há»£p hai bÆ°á»›c: tá»± Ä‘á»™ng trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng vÃ  phÃ¢n loáº¡i trong má»™t láº§n.
- Ãt cÃ´ng sá»©c thá»§ cÃ´ng: khÃ´ng cáº§n con ngÆ°á»i Ä‘á»‹nh nghÄ©a quy táº¯c phá»©c táº¡p.
- Äiá»u kiá»‡n tiÃªn quyáº¿t: cáº§n táº­p dá»¯ liá»‡u gÃ¡n nhÃ£n Ä‘á»§ lá»›n 

**CÃ¡ch tiáº¿p cáº­n dá»±a trÃªn ANN cho phÃ¢n loáº¡i:**
- Input -> Máº¡ng há»c Features -> DÃ¹ng chÃ­nh Ä‘áº·c trÆ°ng Ä‘Ã³ Ä‘á»ƒ phÃ¢n loáº¡i.
- ToÃ n bá»™ quy trÃ¬nh Ä‘Æ°á»£c tá»‘i Æ°u tá»± Ä‘á»™ng qua huáº¥n luyá»‡n, thay vÃ¬ viáº¿t quy táº¯c báº±ng tay.
  
![Neural network based approach for classification](/assets/img/chuong1/figure4.png)

*HÃ¬nh 4: Neural network based approach for classification* 


## II. Hiá»ƒu cÃ¡c khá»‘i cÆ¡ báº£n cá»§a ANN: feedforward, backpropagation, learning rate

**1. Báº£n cháº¥t:**
- ANN lÃ  má»™t hÃ m toÃ¡n há»c gá»“m cÃ¡c trá»ng sá»‘ (weights) vÃ  phÃ©p toÃ¡n sáº¯p xáº¿p thÃ nh má»™t kiáº¿n trÃºc máº¡ng.
- Máº¡ng nháº­n tensor Ä‘áº§u vÃ o â†’ xá»­ lÃ½ qua cÃ¡c lá»›p â†’ xuáº¥t tensor Ä‘áº§u ra.
- Kiáº¿n trÃºc máº¡ng phá»¥ thuá»™c loáº¡i dá»¯ liá»‡u: cÃ³ cáº¥u trÃºc (báº£ng, tabular) hay phi cáº¥u trÃºc (áº£nh, vÄƒn báº£n, Ã¢m thanh).

**2. CÃ¡c lá»›p chÃ­nh trong ANN**
- **Input layer**: nháº­n dá»¯ liá»‡u gá»‘c (vÃ­ dá»¥: pixel áº£nh, Ä‘áº·c trÆ°ng tá»« báº£ng).
- **Hideen Layer**:
  - Biáº¿n Ä‘á»•i dá»¯ liá»‡u tá»« Ä‘áº§u vÃ o
  - Gá»“m nhiá»u nÃºt (nodes), má»—i nÃºt thá»±c hiá»‡n tÃ­nh toÃ¡n.
  - Sá»­ dá»¥ng hÃ m kÃ­ch hoáº¡t (activation function) Ä‘á»ƒ táº¡o phi tuyáº¿n, giÃºp máº¡ng biá»ƒu diá»…n Ä‘Æ°á»£c má»‘i quan há»‡ phá»©c táº¡p.
- **Output Layer**: Ä‘Æ°a ra káº¿t quáº£ cuá»‘i cÃ¹ng (vÃ­ dá»¥: phÃ¢n loáº¡i áº£nh mÃ¨o/ chÃ³, dá»± Ä‘oÃ¡n giÃ¡ trá»‹ sá»‘).
- **TÃ³m láº¡i - ANN** gá»“m: input -> hidden layer -> output, vá»›i Æ°u Ä‘iá»ƒm tá»« hidden layer vÃ  hÃ m kÃ­ch hoáº¡t giÃºp máº¡ng há»c Ä‘Æ°á»£c cÃ¡c Ä‘áº·c trÆ°ng phá»©c táº¡p mÃ  cÃ¡ch thá»§ cÃ´ng khÃ´ng lÃ m Ä‘Æ°á»£c.

![Neural network structure](/assets/img/chuong1/figure5.png)

*HÃ¬nh 5: Neural network structureNeural network structure* 

Sá»‘ lÆ°á»£ng nÃºt (cÃ¡c vÃ²ng trÃ²n á»Ÿ hÃ¬nh trÃªn) á»Ÿ output layer phá»¥ thuá»™c vÃ o bÃ i toÃ¡n cá»¥ thá»ƒ vÃ  viá»‡c chÃºng ta Ä‘ang á»Ÿ bÃ i toÃ¡n nÃ o (dá»± Ä‘oÃ¡n má»™t biáº¿n liÃªn tá»¥c hay phÃ¢n loáº¡i?):
- **BÃ i toÃ¡n há»“i quy (regression)**: dá»± doÃ¡n giÃ¡ trá»‹ liÃªn tá»¥c -> lá»›p Ä‘áº§u ra chá»‰ cÃ³ 1 nÃºt.
- **BÃ i toÃ¡n phÃ¢n loáº¡i (classification)**: dá»± Ä‘oÃ¡n trong m lá»›p -> lá»›p Ä‘áº§u ra cÃ³ m nÃºt, má»—i nÃºt á»©ng vá»›i má»™t lá»›p.

PhÃ³ng to vÃ o **má»™t nÃºt/ nÆ¡-ron**. Má»™t nÆ¡-ron sáº½ biáº¿n Ä‘á»•i input cá»§a nÃ³ theo cÃ¡ch sau: 

![Input transformation at a neuron](/assets/img/chuong1/figure6.png)

*HÃ¬nh 6: Input transformation at a neuron* 

CÃ¡c kÃ­ hiá»‡u trÃªn hÃ¬nh: 
- **Äáº§u vÃ o x_1, x_2, x_n** : cÃ¡c biáº¿n Ä‘áº§u vÃ o
- **W_0: lÃ  há»‡ sá»‘ chá»‡ch (bias term)** (giÃºp mÃ´ hÃ¬nh linh hoáº¡t, giá»‘ng trong bÃ i toÃ¡n há»“i quy tuyáº¿n tÃ­nh hoáº·c logistic).
- **W_1, W_2, W_3,â€¦ W_n**: lÃ  cÃ¡c trá»ng sá»‘ gÃ¡n cho tá»«ng biáº¿n Ä‘áº§u vÃ o, vÃ  W_0 lÃ  há»‡ sá»‘ chá»‡ch.
- **GiÃ¡ trá»‹ Ä‘áº§u ra (output) a** Ä‘Æ°á»£c tÃ­nh nhÆ° sau:
$$
\\( a = f(w_0 + \sum_{i=1}^n w_i x_i) \\)
$$
- Trong Ä‘Ã³, **f lÃ  hÃ m kÃ­ch hoáº¡t (activation function)**
NghÄ©a lÃ : **Ä‘áº§u vÃ o (x_1, x_2â€¦x_n) Ã— trá»ng sá»‘ (W_1, W_2, W_3,â€¦ W_n) + bias (W_0) â†’ qua hÃ m kÃ­ch hoáº¡t (f) â†’ ra Ä‘áº§u ra  - output (a) cá»§a nÆ¡-ron**.
**Ã nghÄ©a cá»§a hÃ m kÃ­ch hoáº¡t.**
- Táº¡o tÃ­nh phi tuyáº¿n, giÃºp máº¡ng há»c Ä‘Æ°á»£c cÃ¡c quan há»‡ phá»©c táº¡p (náº¿u chá»‰ tuyáº¿n tÃ­nh thÃ¬ máº¡ng giá»‘ng há»‡t há»“i quy tuyáº¿n tÃ­nh)
- CÃ³ nhiá»u loáº¡i hÃ m kÃ­ch hoáº¡t (sigmoid, tanh, ReLUâ€¦) sáº½ há»c ká»¹ hÆ¡n trong pháº§n feedforward.
- **Khi má»™t máº¡ng nÆ¡ ron cÃ³ nhiá»u lá»›p áº©n (hidden layers) thÃ¬ ta gá»i nÃ³ lÃ  deep learning.**
- **Nhiá»‡m vá»¥ cÃ ng phá»©c táº¡p -> cáº§n nhiá»u lá»›p áº©n hÆ¡n Ä‘á»ƒ xá»­ lÃ½ - vÃ­ dá»¥ nhÆ° nháº­n diá»‡n hÃ¬nh áº£nh.**

## III. Implementing feedforward propagation
- Äá»ƒ xÃ¢y dá»±ng ná»n táº£ng vá»¯ng cháº¯c vá» cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a lan truyá»n tiáº¿n (feedforward propagation), ta sáº½ xÃ©t vÃ­ dá»¥ cÆ¡ báº£n sau vá» viá»‡c huáº¥n luyá»‡n máº¡ng nÆ¡-ron. 
- Trong vÃ­ dá»¥ nÃ y, Ä‘áº§u vÃ o cá»§a máº¡ng nÆ¡-ron lÃ  (1,1) vÃ  Ä‘áº§u ra tÆ°Æ¡ng á»©ng mong Ä‘á»£i lÃ  (0). á» Ä‘Ã¢y, ta sáº½ tÃ¬m cÃ¡c trá»ng sá»‘ tá»‘i Æ°u cá»§a máº¡ng nÆ¡-ron dá»±a trÃªn cáº·p dá»¯ liá»‡u input vÃ  output Ä‘Ã£ cho.
- Kiáº¿n trÃºc máº¡ng nÆ¡-ron cá»§a chÃºng ta trong vÃ­ dá»¥ nÃ y bao gá»“m má»™t lá»›p áº©n vá»›i ba nÃºt nhÆ° sau: 

![Sample neural network architecture with 1 hidden layer](/assets/img/chuong1/figure7.png)

*HÃ¬nh 7: Sample neural network architecture with 1 hidden layer* 

- XÃ©t hÃ¬nh 7:
  - **Má»—i mÅ©i tÃªn = má»™t trá»ng sá»‘ (float)** cÃ³ thá»ƒ Ä‘iá»u chá»‰nh.
  - CÃ³ 6 trá»ng sá»‘ tá»« 2 nÃºt Ä‘áº§u vÃ o -> 3 nÃºt áº©n.
  - CÃ³ 3 trá»ng sá»‘ tá»« 3 nÃºt áº©n -> 1 nÃºt Ä‘áº§u ra.
  - Tá»•ng cá»™ng 9 trá»ng sá»‘ cáº§n há»c.
- **Má»¥c tiÃªu huáº¥n luyá»‡n: tÃ¬m ra giÃ¡ trá»‹ cá»§a 9 trá»ng sá»‘ nÃ y sao cho: Input = (1,1) => Output = 0.**
- á» Ä‘Ã¢y chÆ°a xÃ©t bias Ä‘á»ƒ giá»¯ cho vÃ­ dá»¥ Ä‘Æ¡n giáº£n, logic váº«n Ä‘Ãºng.
CÃ¡c bÆ°á»›c tiáº¿p theo cáº§n tÃ¬m hiá»ƒu:
- TÃ­nh toÃ¡n lá»›p áº©n: Ä‘áº§u vÃ o nhÃ¢n vá»›i trá»ng sá»‘ â†’ ra giÃ¡ trá»‹ trung gian.
- HÃ m kÃ­ch hoáº¡t phi tuyáº¿n: biáº¿n Ä‘á»•i cÃ¡c giÃ¡ trá»‹ trung gian Ä‘á»ƒ máº¡ng há»c Ä‘Æ°á»£c quan há»‡ phá»©c táº¡p.
- Æ¯á»›c lÆ°á»£ng lá»›p Ä‘áº§u ra: tá»« lá»›p áº©n â†’ Ä‘áº§u ra dá»± Ä‘oÃ¡n.
- HÃ m máº¥t mÃ¡t (Loss function): so sÃ¡nh Ä‘áº§u ra dá»± Ä‘oÃ¡n vá»›i Ä‘áº§u ra mong Ä‘á»£i (expected output).

**TÃNH TOÃN TRá»ŒNG Sá» CHO VÃ Dá»¤ HÃŒNH 7**
- GÃ¡n trá»ng sá»‘ cho táº¥t cáº£ cÃ¡c káº¿t ná»‘i (thÃ´ng thÆ°á»ng, cÃ¡c máº¡ng nÆ¡-ron Ä‘Æ°á»£c khá»Ÿi táº¡o báº±ng cÃ¡c trá»ng sá»‘ ngáº«u nhiÃªn trÆ°á»›c khi quÃ¡ trÃ¬nh huáº¥n luyá»‡n báº¯t Ä‘áº§u).
-	Ban Ä‘áº§u â€“ bÆ°á»›c khá»Ÿi táº¡o - cÃ¡c trá»ng sá»‘ thÆ°á»ng Ä‘Æ°á»£c gÃ¡n ngáº«u nhiÃªn (vÃ­ dá»¥ trong khoáº£ng [0,1].
-	Trong vÃ­ dá»¥ nÃ y, ta bá» qua bias Ä‘á»ƒ táº­p trung vÃ o cÆ¡ cháº¿ feedforward vÃ  backpropagation.

![GanTrongSo](/assets/img/chuong1/figure8.png)

*HÃ¬nh 8: GÃ¡n trá»ng sá»‘ & khá»Ÿi táº¡o ngáº«u nhiÃªn* 

- CÃ¡c trá»ng sá»‘ vÃ  giÃ¡ trá»‹ trong máº¡ng Ä‘Æ°á»£c thá»ƒ hiá»‡n á»Ÿ sÆ¡ Ä‘á»“ sau (ná»­a bÃªn trÃ¡i), vÃ  cÃ¡c trá»ng sá»‘ khá»Ÿi táº¡o ngáº«u nhiÃªn Ä‘Æ°á»£c minh há»a trong máº¡ng á»Ÿ ná»­a bÃªn pháº£i.
- á» bÆ°á»›c tiáº¿p theo, ta thá»±c hiá»‡n phÃ©p nhÃ¢n giá»¯a input vÃ  cÃ¡c trá»ng sá»‘ Ä‘á»ƒ tÃ­nh toÃ¡n cÃ¡c giÃ¡ trá»‹ cá»§a cÃ¡c Ä‘Æ¡n vá»‹ trong lá»›p áº©n. CÃ¡c giÃ¡ trá»‹ cá»§a cÃ¡c Ä‘Æ¡n vá»‹ trong lá»›p áº©n trÆ°á»›c khi Ã¡p dá»¥ng hÃ m kÃ­ch hoáº¡t (activation) Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh nhÆ° sau: 

$$
h_11= X_1Ã— W_11+ X_2Ã—W_21=1Ã—0.8+1 Ã—0.2=1
$$
$$
h_12= X_1Ã— W_12+ X_2Ã—W_22=1Ã—0.4+1 Ã—0.9=1.3
$$
$$
h_13= X_1Ã— W_13+ X_2Ã—W_23=1Ã—0.3+1 Ã—0.5=0.8
$$

- Káº¿t quáº£ cá»§a cÃ¡c Ä‘Æ¡n vá»‹ trong hidden layer (trÆ°á»›c khi Ã¡p dá»¥ng hÃ m kÃ­ch hoáº¡t) sau khi tÃ­nh toÃ¡n xong á»Ÿ trÃªn:

![TinhToan](/assets/img/chuong1/figure9.png)

*HÃ¬nh 9: Káº¿t quáº£ cuá»‘i cÃ¹ng trÆ°á»›c khi Ã¡p dá»¥ng hÃ m kÃ­ch hoáº¡t* 





